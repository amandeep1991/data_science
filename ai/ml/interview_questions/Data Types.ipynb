{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an imbalanced dataset? Can you list some ways to deal with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An imbalanced dataset is one that has different proportions of target categories. \n",
    "\n",
    "For example, a dataset with medical images where we have to detect some illness will typically have many more negative samples than positive samples—say, 98% of images are without the illness and 2% of images are with the illness.\n",
    "\n",
    "\n",
    "Imbalance is Common: \n",
    "    There are problems where a class imbalance is not just common, it is expected. For example, in datasets like those that characterize fraudulent transactions are imbalanced. The vast majority of the transactions will be in the “Not-Fraud” class and a very small minority will be in the “Fraud” class.\n",
    "    Another example is customer churn datasets, where the vast majority of customers stay with the service (the “No-Churn” class) and a small minority cancel their subscription (the “Churn” class).\n",
    "    \n",
    "\n",
    "Accuracy Paradox concept applies to such situations. \n",
    "\n",
    "\n",
    "There are different options to deal with imbalanced datasets:\n",
    "\n",
    "    1. Collect more data: This tactic is mostly over-looked. A larger dataset might expose a different and perhaps more balanced perspective on the classes.\n",
    "    \n",
    "    \n",
    "    \n",
    "    2. Try Resampling Your Dataset (Oversampling or undersampling): Instead of sampling with a uniform distribution from the training dataset, we can use other distributions so the model sees a more balanced dataset.\n",
    "        There are two main methods that you can use to even-up the classes:\n",
    "            1. You can add copies of instances from the under-represented class called over-sampling (or more formally sampling with replacement), or\n",
    "            2. You can delete instances from the over-represented class, called under-sampling.\n",
    "        Some Rules of Thumb\n",
    "            1. Consider testing under-sampling when you have an a lot data (tens- or hundreds of thousands of instances or more)\n",
    "            2. Consider testing over-sampling when you don’t have a lot of data (tens of thousands of records or less)\n",
    "            3. Consider testing random and non-random (e.g. stratified) sampling schemes.\n",
    "            4. Consider testing different resampled ratios (e.g. you don’t have to target a 1:1 ratio in a binary classification problem, try other ratios)\n",
    "    \n",
    "    3. Data augmentation (Try Generate Synthetic Samples) : We can add data in the less frequent categories by modifying existing data in a controlled way. In the example dataset, we could flip the images with illnesses, or add noise to copies of the images in such a way that the illness remains visible.\n",
    "        There are systematic algorithms that you can use to generate synthetic samples. The most popular of such algorithms is called SMOTE or the Synthetic Minority Over-sampling Technique.\n",
    "        As its name suggests, SMOTE is an oversampling method. It works by creating synthetic samples from the minor class instead of creating copies. The algorithm selects two or more similar instances (using a distance measure) and perturbing an instance one attribute at a time by a random amount within the difference to the neighboring instances.\n",
    "    \n",
    "    4. Using appropriate metrics (try changing performance matrics): In the example dataset, if we had a model that always made negative predictions, it would achieve a precision of 98%. There are other metrics such as precision, recall, and F-score that describe the accuracy of the model better when using an imbalanced dataset.\n",
    "            Possible Metrics - Confusion Matrix, Precision, REcall, F1 score, Kappa, ROC Curves etc.\n",
    "            \n",
    "            \n",
    "    5. Try different Algorithms: Not use your favorite algorithm on every problem. \n",
    "                Decision trees often perform well on imbalanced datasets. The splitting rules that look at the class variable used in the creation of the trees, can force both classes to be addressed.\n",
    "                If in doubt, try a few popular decision tree algorithms like C4.5, C5.0, CART, and Random Forest.\n",
    "                \n",
    "                \n",
    "    6. Try Penalized Models: You can use the same algorithms but give them a different perspective on the problem.\n",
    "                Penalized classification imposes an additional cost on the model for making classification mistakes on the minority class during training. These penalties can bias the model to pay more attention to the minority class.\n",
    "                Often the handling of class penalties or weights are specialized to the learning algorithm. There are penalized versions of algorithms such as penalized-SVM and penalized-LDA.\n",
    "                Using penalization is desirable if you are locked into a specific algorithm and are unable to resample or you’re getting poor results. It provides yet another way to “balance” the classes. Setting up the penalty matrix can be complex. You will very likely have to try a variety of penalty schemes and see what works best for your problem.\n",
    "                 \n",
    "                                \n",
    "    7. Try a Different Perspective: Taking a look and thinking about your problem from these perspectives can sometimes shame loose some ideas. Two you might like to consider are anomaly detection and change detection.\n",
    "        1. Anomaly detection is the detection of rare events. This might be a machine malfunction indicated through its vibrations or a malicious activity by a program indicated by it’s sequence of system calls. The events are rare and when compared to normal operation.\n",
    "            This shift in thinking considers the minor class as the outliers class which might help you think of new ways to separate and classify samples.\n",
    "        2. Change detection is similar to anomaly detection except rather than looking for an anomaly it is looking for a change or difference. This might be a change in behavior of a user as observed by usage patterns or bank transactions.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is data augmentation? Can you give some examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.\n",
    "\n",
    "Computer vision is one of fields where data augmentation is very useful. There are many modifications that we can do to images:\n",
    "\n",
    "    Resize\n",
    "    Horizontal or vertical flip\n",
    "    Rotate\n",
    "    Add noise\n",
    "    Deform\n",
    "    Modify colors\n",
    "    \n",
    "Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
