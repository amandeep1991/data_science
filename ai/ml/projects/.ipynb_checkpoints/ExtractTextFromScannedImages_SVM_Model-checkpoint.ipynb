{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True # To enable intellisense in Jupyter Notebook\n",
    "# to make matplotlib figures inline\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import neccessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility Methods\n",
    "\n",
    "def show_high_resolution_picture_in_two_parts(image_in_numpy_format):\n",
    "    height, width = image_in_numpy_format.shape[:2]\n",
    "    \n",
    "    if len(image_in_numpy_format.shape)==3:\n",
    "        cv2.imshow(\"Input Image (without any preprocessing)\", cv2.resize(image_in_numpy_format[:height//2, :, :], (0,0), fx=0.4, fy=0.4)) \n",
    "        cv2.waitKey() #This is required for showing opencv images\n",
    "        cv2.imshow(\"Input Image (without any preprocessing)\", cv2.resize(image_in_numpy_format[height//2:, :, :], (0,0), fx=0.4, fy=0.4)) \n",
    "        cv2.waitKey() #This is required for showing opencv images\n",
    "    else:\n",
    "        cv2.imshow(\"Input Image (without any preprocessing)\", cv2.resize(image_in_numpy_format[:height//2, :], (0,0), fx=0.4, fy=0.4)) \n",
    "        cv2.waitKey() #This is required for showing opencv images\n",
    "        cv2.imshow(\"Input Image (without any preprocessing)\", cv2.resize(image_in_numpy_format[height//2:, :], (0,0), fx=0.4, fy=0.4)) \n",
    "        cv2.waitKey() #This is required for showing opencv images\n",
    "\n",
    "    # Drawing the image using matplotlib will give options to zoom-in or zoom-out (so better for analysis)\n",
    "    # plt.imshow(input_image[:height/2, :width/2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3520, 2480, 3)\n",
      "(3520, 2480, 3)\n",
      "Shape of imgray:: (3520, 2480)\n",
      "Shape of Thresholded image:: (3520, 2480)\n",
      "Successfully executed\n"
     ]
    }
   ],
   "source": [
    "# Read input Form\n",
    "\n",
    "scanned_form_image_path = \"data/ScannedForm_For_TextExtraction.jpg\"\n",
    "\n",
    "input_image = cv2.imread(scanned_form_image_path)\n",
    "\n",
    "image_shape = input_image.shape\n",
    "height, width, channels_count = image_shape\n",
    "\n",
    "print(image_shape)\n",
    "\n",
    "show_high_resolution_picture_in_two_parts(input_image)\n",
    "\n",
    "print(image_shape)\n",
    "\n",
    "\n",
    "image_to_be_processed = input_image.copy()\n",
    "\n",
    "\n",
    "imgray = cv2.cvtColor(image_to_be_processed, cv2.COLOR_BGR2GRAY)\n",
    "print(\"Shape of imgray::\", imgray.shape)\n",
    "\n",
    "# Different types are:\n",
    "#    cv2.THRESH_BINARY (0): \n",
    "#    cv2.THRESH_BINARY_INV (1): \n",
    "#    cv2.THRESH_TRUNC (2): \n",
    "#    cv2.THRESH_TOZERO (3): \n",
    "#    cv2.THRESH_TOZERO_INV (4): \n",
    "\n",
    "\n",
    "\n",
    "# Adaptive Thresholding: we used a global value as threshold value. But it may not be good in all the conditions where image has different lighting conditions in different areas. In that case, we go for adaptive thresholding.\n",
    "# Adaptive Method - It decides how thresholding value is calculated.\n",
    "#       cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.\n",
    "#       cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
    "\n",
    "ret, image_after_thresholding = cv2.threshold(imgray, 127, 255, 0)\n",
    "print(\"Shape of Thresholded image::\", image_after_thresholding.shape)\n",
    "\n",
    "\n",
    "show_high_resolution_picture_in_two_parts(image_after_thresholding)\n",
    "\n",
    "# def findContours(image, (Contour retrieval mode), (Contour approximation method), contours=None, hierarchy=None, offset=None)\n",
    "# Contour retrieval mode: cv2.RETR_LIST, RETR_EXTERNAL, cv2.RETR_CCOMP, RETR_TREE\n",
    "# Contour approximation method: cv2.CHAIN_APPROX_NONE, cv2.CHAIN_APPROX_SIMPLE\n",
    "# Pre-requisite - cvtColor (otherwise throw error - FindContours supports only CV8UC1 images)\n",
    "_, contours_ds, _ = cv2.findContours(image_after_thresholding, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\n",
    "for contour in contours_ds:\n",
    "    (x,y,w,h) = cv2.boundingRect(contour)\n",
    "    # image_after_thresholding = cv2.cvtColor(image_after_thresholding, cv2.CV_GRAY2BGR)\n",
    "    cv2.rectangle(image_to_be_processed, (x,y), (x+w,y+h), (0,0,255), 2)\n",
    "\n",
    "show_high_resolution_picture_in_two_parts(image_to_be_processed)    \n",
    "    \n",
    "# MINUS_ONE_signifies_to_draw_all_contours=-1\n",
    "# width_integer=10\n",
    "# image_drawing_contours = cv2.drawContours(image_after_thresholding, contours_ds, MINUS_ONE_signifies_to_draw_all_contours, (0,0,255), width_integer)\n",
    "\n",
    "# print(image_drawing_contours)\n",
    "# print(type(image_drawing_contours))\n",
    "# show_high_resolution_picture_in_two_parts(image_drawing_contours)\n",
    "\n",
    "\n",
    "print(\"Successfully executed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
