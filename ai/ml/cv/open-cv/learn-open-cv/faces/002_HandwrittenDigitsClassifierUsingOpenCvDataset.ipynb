{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![open-cv inbuilt dataset](img/06_digits-1024x512.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the above image as our dataset that comes with OpenCV samples. \n",
    "\n",
    "It contains 5000 images in all — 500 images of each digit. \n",
    "\n",
    "Each image is 20×20 grayscale with a black background. \n",
    "\n",
    "4500 of these digits will be used for training and the remaining 500 will be used for testing the performance of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Deskewing (Pre-Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People often think of a learning algorithm as a block box.\n",
    "\n",
    "In reality, you can assist the algorithm a bit and notice huge gains in performance. For example, if you are building a face recognition system, aligning the images to a reference face often leads to a quite substantial improvement in performance.\n",
    "\n",
    "Aligning digits before building a classifier similarly produces superior results. In the case of faces, aligment is rather obvious — you can apply a similarity transformation to an image of a face to align the two corners of the eyes to the two corners of a reference face.\n",
    "\n",
    "In the case of handwritten digits, an obvious variation in writing among people is the slant of their writing. Some writers have a right or forward slant where the digits are slanted forward, some have a backward or left slant, and some have no slant at all. We can help the algorithm quite a bit by fixing this vertical slant so it does not have to learn this variation of the digits. The image on the left shows the original digit in the first column and it’s deskewed (fixed) version.\n",
    "\n",
    "This deskewing of simple grayscale images can be achieved using image moments (an image moment is a certain particular weighted average (moment) of the image pixels' intensities, or a function of such moments, usually chosen to have some attractive property or interpretation.) - [Raw Moments, Central Moments, Moment Invariants]. \n",
    "OpenCV has an implementation of moments and it comes in handy while calculating useful information like centroid, area, skewness of simple images with black backgrounds.\n",
    "\n",
    "\n",
    "It turns out that a measure of the skewness is the given by the ratio of the two central moments ( mu11 / mu02 ). The skewness thus calculated can be used in calculating an affine transform that deskews the image.\n",
    "\n",
    "@Affine Tranformation:-\n",
    "    1. Origin doesn't necessary map to origin\n",
    "    2. Lines map to lines.\n",
    "    3. Parallel lines remain parallel\n",
    "    4. Ratio are preserved\n",
    "\n",
    "        def deskew(img):\n",
    "            m = cv2.moments(img)\n",
    "            if abs(m['mu02']) < 1e-2:\n",
    "                # no deskewing needed. \n",
    "                return img.copy()\n",
    "            #// Calculate skew based on central momemts. \n",
    "            skew = m['mu11']/m['mu02']\n",
    "            #// Calculate affine transform to correct skewness. \n",
    "            M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "            #// Apply affine transform\n",
    "            img = cv2.warpAffine(img, M, (SZ, SZ), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Calculate the Histogram of Oriented Gradients (HOG) descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the grayscale image to a feature vector using the HOG feature descriptor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering information is easy but the difficult part is putting that knowledge into Practise. \n",
    "\n",
    "Part of the reason was that a lot of these algorithms worked after tedious handtuning and it was not obvious how to set the right parameters. For example, in Harris corner detector, why is the free parameter k set to 0.04 ? Why not 1 or 2 or 0.34212 instead? Why is 42 the answer to life, universe, and everything?\n",
    "\n",
    "As I got more real world experience, I realized that in some cases you can make an educated guess but in other cases, nobody knows why. People often do a parameter sweep — they change different parameters in a principled way to see what produces the best result. Sometimes, the best parameters have an intuitive explanation and sometimes they don’t.\n",
    "\n",
    "\n",
    "    winSize = (20,20) ##set to 20×20 (size of the digit images) & want to calculate 1 descriptor for the entire image.\n",
    "        \n",
    "    blockSize = (10,10)\n",
    "    blockStride = (5,5)\n",
    "    \n",
    "    ## The cellSize is chosen based on the scale of the features important to do the classification. \n",
    "    ## A very small value would blow up the size of feature vector & very large one may not capture relevant information.\n",
    "    ## 8 value could have been used.\n",
    "    cellSize = (10,10) \n",
    "    \n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = -1.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 0.2\n",
    "    gammaCorrection = 1\n",
    "    nlevels = 64\n",
    "    signedGradients = True\n",
    "    \n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType, L2HysThreshold,gammaCorrection,nlevels, useSignedGradients)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
