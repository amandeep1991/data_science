{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Dependencies for this notebook:\n<br>\n* pip install spacy, pandas, matplotlib\n* python -m spacy.en.download\n\n    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "#encode some text as uncode\n",
    "text = u\"I'm executing this code on an Apple Computer.\"\n",
    "\n",
    "#instantiate a language model\n",
    "#to download language model: python -m spacy.en.download \n",
    "nlp = spacy.load('en') # or spacy.en.English()\n",
    "\n",
    "#create a document\n",
    "document = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "for function in nlp.pipeline:\n",
    "    print(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "### Modifying the Language Model\n",
    "def identify_starwars(doc):\n",
    "    for token in doc:\n",
    "        if token.text == u'starwars':\n",
    "            token.tag_ = u'NNP'\n",
    "\n",
    "def return_pipeline(nlp):\n",
    "    return [nlp.tagger, nlp.parser, nlp.matcher, nlp.entity, identify_starwars]\n",
    "\n",
    "text = u\"I loved all of the starwars movies\"\n",
    "custom_nlp = spacy.load('en', create_pipeline=return_pipeline)\n",
    "new_document = custom_nlp(text)\n",
    "\n",
    "for function in custom_nlp.pipeline:\n",
    "    print(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "texts = [u'You have brains in your head.'] * 10000\n",
    "\n",
    "\n",
    "for doc in nlp.pipe(texts,n_threads=4):\n",
    "    doc.is_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "### Deploying Model on Many Texts with .pipe\n",
    "runtimes = {}\n",
    "\n",
    "for thread_count in [1,2,3,4,8]:\n",
    "    t0 =  datetime.now() \n",
    "    \n",
    "    #Create generator of processed documents\n",
    "    processed_documents = nlp.pipe(texts,n_threads=thread_count)\n",
    "    \n",
    "    #Iterate over generator\n",
    "    for doc in processed_documents: \n",
    "        \n",
    "        #pipeline is only run once we access the generator\n",
    "        doc.is_parsed \n",
    "    \n",
    "    t1 = datetime.now()\n",
    "    runtimes[thread_count] = (t1 - t0).total_seconds()\n",
    "    \n",
    "ax = pd.Series(runtimes).plot(kind = 'bar')\n",
    "ax.set_ylabel(\"Runtime (Seconds) with N Threads\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Accessing Tokens and Spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def info(obj):\n",
    "    return {'type':type(obj),'__str__': str(obj)}\n",
    "\n",
    "\n",
    "text = u\"\"\"spaCy excels at large-scale information extraction tasks. \n",
    "It's written from the ground up in carefully memory-managed Cython. \"\"\"\n",
    "document = nlp(text)\n",
    "token = document[0]\n",
    "span = document[0:3]\n",
    "\n",
    "\n",
    "pd.DataFrame(map(info, [token,span,document]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Sentence boundary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "print(document.sents)\n",
    "print\n",
    "for sent in document.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "for token in document:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Morphological decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "token = document[13]\n",
    "print(\"text: %s\" % token.text)\n",
    "print(\"suffix: %s\" % token.suffix_) \n",
    "print(\"lemma: %s\" % token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "#Part of speech and Dependency tagging\n",
    "attrs = map(lambda token: {\n",
    "                     \"token\":token\n",
    "                   , \"part of speech\":token.pos_\n",
    "                   , \"Dependency\" : token.dep_}\n",
    "                    , document)\n",
    "pd.DataFrame(attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Noun Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "print(\"noun chunks: {}\".format(list(document.noun_chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "ents = [(ent, ent.root.ent_type_) for ent in document.ents]\n",
    "print(\"entities: {}\".format(ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Text Similarity (Using Word Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "#document, span, and token similarity\n",
    "def plot_similarities(similarities, target):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    f, ax = plt.subplots(1)\n",
    "    index = range(len(similarities))\n",
    "    ax.barh(index, similarities)\n",
    "    ax.set_yticks([i + 0. for i in index])\n",
    "    ax.set_yticklabels(document2)\n",
    "    ax.grid(axis='x')\n",
    "    ax.set_title(\"Similarity to '{}'\".format(target))\n",
    "    plt.show()\n",
    "    return ax\n",
    "    \n",
    "    \n",
    "computer = nlp(u'computer')\n",
    "document2 = nlp(u'You might be using a machine running Windows')\n",
    "similarities = map(lambda token: token.similarity(computer),document2)\n",
    "ax = plot_similarities(similarities, computer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "pygments_lexer": "ipython2",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "2.7.12",
   "file_extension": ".py",
   "name": "python",
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python"
  },
  "_datascience": {
   "notebookId": 747.0
  },
  "kernelspec": {
   "language": "python",
   "name": "python2",
   "display_name": "Python 2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
