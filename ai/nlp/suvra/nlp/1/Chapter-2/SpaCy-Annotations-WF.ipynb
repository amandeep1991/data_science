{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Dependencies\n* pip install spacy, pandas, matplotlib, pathlib\n* python -m spacy.en.download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('/home/jupyter/site-packages/')\n",
    "from IPython.display import SVG, display\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Accessing Tokens and Spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "_datascience": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>__str__</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>spaCy</td>\n      <td>&lt;type 'spacy.tokens.token.Token'&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>spaCy excels at</td>\n      <td>&lt;type 'spacy.tokens.span.Span'&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spaCy excels at large-scale information extrac...</td>\n      <td>&lt;type 'spacy.tokens.doc.Doc'&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "                                             __str__  \\\n0                                              spaCy   \n1                                    spaCy excels at   \n2  spaCy excels at large-scale information extrac...   \n\n                                type  \n0  <type 'spacy.tokens.token.Token'>  \n1    <type 'spacy.tokens.span.Span'>  \n2      <type 'spacy.tokens.doc.Doc'>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def info(obj):\n",
    "    return {'type':type(obj),'__str__': str(obj)}\n",
    "\n",
    "\n",
    "text = u\"\"\"spaCy excels at large-scale information extraction tasks. \n",
    "It's written from the ground up in carefully memory-managed Cython. \"\"\"\n",
    "document = nlp(text)\n",
    "token = document[0]\n",
    "span = document[0:3]\n",
    "\n",
    "\n",
    "pd.DataFrame(map(info, [token,span,document]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Sentence boundary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "_datascience": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object at 0x7efbd365a738>\nspaCy excels at large-scale information extraction tasks. \n\nIt's written from the ground up in carefully memory-managed Cython.\n"
     ]
    }
   ],
   "source": [
    "print(document.sents)\n",
    "for sent in document.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "_datascience": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy\nexcels\nat\nlarge\n-\nscale\ninformation\nextraction\ntasks\n.\n\n\nIt\n's\nwritten\nfrom\nthe\nground\nup\nin\ncarefully\nmemory\n-\nmanaged\nCython\n.\n"
     ]
    }
   ],
   "source": [
    "for token in document:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "### Morphological decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "token = document[13]\n",
    "print(\"text: %s\" % token.text)\n",
    "print(\"suffix: %s\" % token.suffix_) \n",
    "print(\"lemma: %s\" % token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "### Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "#Part of speech and Dependency tagging\n",
    "attrs = map(lambda token: {\n",
    "                     \"token\":token\n",
    "                   , \"part of speech\":token.pos_\n",
    "                   , \"Dependency\" : token.dep_}\n",
    "                    , document)\n",
    "pd.DataFrame(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "### Noun Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "print(\"noun chunks: {}\".format(list(document.noun_chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "ents = [(ent, ent.root.ent_type_) for ent in document.ents]\n",
    "print(\"entities: {}\".format(ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "### Text Similarity (Using Word Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "#document, span, and token similarity\n",
    "def plot_similarities(similarities, target):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    f, ax = plt.subplots(1)\n",
    "    index = range(len(similarities))\n",
    "    ax.barh(index, similarities)\n",
    "    ax.set_yticks(index)\n",
    "    ax.set_yticklabels(document2)\n",
    "    ax.grid(axis='x')\n",
    "    ax.set_title(\"Similarity to '{}'\".format(target))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "computer = nlp(u'computer')\n",
    "document2 = nlp(u'You might be using a machine running Windows')\n",
    "similarities = map(lambda token: token.similarity(computer),document2)\n",
    "plot_similarities(similarities, computer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "_datascience": {
   "notebookId": 748.0
  },
  "kernelspec": {
   "language": "python",
   "name": "python2",
   "display_name": "Python 2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
