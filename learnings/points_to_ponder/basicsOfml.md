* *Non-stationary data*:
>* It is, conceptually, data that is very difficult to model because the estimate of the mean will be changing [and sometimes the variance]. Sometimes, this is a really good thing, because you can find artifacts that cause it. Other times, it is minor and due to the vicissitudes of chance. Typically, time-series analysts take differences of the data [i.e. today minus yesterday to the n] to analyze this problem and discover said artifacts.
>* There are a huge number of time series modeling techniques, but they generally depend (or perform best) upon stationary data. The convolution of a time variate will make your information less decipherable. However, if you can remove and isolate it, you can predict with great accuracy by making it stationary and de-stationary..ing it after the predictions.

* What is the difference between cross-validation and grid search?
>* Cross-validation is when you reserve part of your data to use in evaluating your model. There are different cross-validation methods. The simplest conceptually is to just take 70% (just making up a number here, it doesn't have to be 70%) of your data and use that for training, and then use the remaining 30% of the data to evaluate the model's performance. The reason you need different data for training and evaluating the model is to protect against overfitting. There are other (slightly more involved) cross-validation techniques, of course, like k-fold cross-validation, which often used in practice.
>* Grid search is a method to perform hyper-parameter optimisation, that is, it is a method to find the best combination of hyper-parameters (an example of an hyper-parameter is the learning rate of the optimiser), for a given model (e.g. a CNN) and test dataset. In this scenario, you have several models, each with a different combination of hyper-parameters. Each of these combinations of parameters, which correspond to a single model, can be said to lie on a point of a "grid". The goal is then to train each of these models and evaluate them e.g. using cross-validation. You then select the one that performed best.